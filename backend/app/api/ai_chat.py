from fastapi import APIRouter, Depends, HTTPException, Request, Body
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import json

from app.database import get_db
from app.services.ai_service import AIService
from app.api.settings import get_user_ai_service
from app.utils.sse_response import create_sse_response
from app.logger import get_logger
from app.models.project import Project
from app.models.chapter import Chapter
from app.api.chapters import verify_project_access

router = APIRouter(prefix="/ai", tags=["AIåŠ©æ‰‹"])
logger = get_logger(__name__)

class ChatRequest(BaseModel):
    project_id: str = Field(..., description="é¡¹ç›®ID")
    chapter_id: Optional[str] = Field(None, description="å½“å‰ç« èŠ‚ID")
    prompt: str = Field(..., description="ç”¨æˆ·è¾“å…¥çš„æŒ‡ä»¤æˆ–é—®é¢˜")
    selected_text: Optional[str] = Field(None, description="ç”¨æˆ·åœ¨ç¼–è¾‘å™¨ä¸­é€‰ä¸­çš„æ–‡æœ¬")
    context_text: Optional[str] = Field(None, description="ç¼–è¾‘å™¨ä¸­çš„ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆå¦‚å…‰æ ‡å‰åå†…å®¹ï¼‰")
    use_mcp: bool = Field(True, description="æ˜¯å¦å¯ç”¨MCPå·¥å…·å¢å¼º")

@router.post("/chat", summary="AIå†™ä½œåŠ©æ‰‹å¯¹è¯")
async def chat_with_ai(
    request: Request,
    chat_req: ChatRequest,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    AIå†™ä½œåŠ©æ‰‹å¯¹è¯æ¥å£ï¼ˆæ”¯æŒæµå¼å“åº”ï¼‰
    """
    user_id = getattr(request.state, 'user_id', None)
    if not user_id:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")

    # éªŒè¯é¡¹ç›®æƒé™
    project = await verify_project_access(chat_req.project_id, user_id, db)
    
    # è·å–ç« èŠ‚ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†chapter_idï¼‰
    chapter_info = ""
    if chat_req.chapter_id:
        result = await db.execute(select(Chapter).where(Chapter.id == chat_req.chapter_id))
        chapter = result.scalar_one_or_none()
        if chapter:
            chapter_info = f"å½“å‰ç« èŠ‚ï¼šç¬¬{chapter.chapter_number}ç«  {chapter.title}\n"

    # æ„å»º System Prompt
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘æ–‡å†™ä½œåŠ©æ‰‹ (Copilot)ã€‚ä½ çš„ç›®æ ‡æ˜¯è¾…åŠ©ä½œè€…åˆ›ä½œï¼Œæä¾›çµæ„Ÿã€æ¶¦è‰²æ–‡æœ¬æˆ–å›ç­”è®¾å®šé—®é¢˜ã€‚

ã€é¡¹ç›®ä¿¡æ¯ã€‘
ä¹¦åï¼š{project.title}
ç±»å‹ï¼š{project.genre or 'æœªè®¾å®š'}
èƒŒæ™¯ï¼š{project.world_time_period or 'æœªè®¾å®š'} {project.world_location or 'æœªè®¾å®š'}

{chapter_info}

ã€é‡è¦è§„åˆ™ã€‘
1. ğŸ¯ **ç²¾å‡†æ‰§è¡Œ**ï¼šåªæ‰§è¡Œç”¨æˆ·çš„å…·ä½“æŒ‡ä»¤ã€‚å¦‚æœç”¨æˆ·è¦æ±‚â€œæ¶¦è‰²â€ï¼Œå°±åªè¾“å‡ºæ¶¦è‰²åçš„æ®µè½ï¼Œä¸è¦ç»­å†™åç»­å‰§æƒ…ã€‚
2. ğŸš« **ä¸¥ç¦å¤è¯»**ï¼šä¸è¦é‡å¤ç”¨æˆ·æä¾›çš„ã€å‚è€ƒèƒŒæ™¯ã€‘å†…å®¹ã€‚
3. âœ‚ï¸ **èŒƒå›´æ§åˆ¶**ï¼šå¦‚æœæä¾›äº†ã€å¾…å¤„ç†æ–‡æœ¬ã€‘ï¼Œè¯·ä»…å¯¹è¯¥æ–‡æœ¬è¿›è¡Œæ“ä½œã€‚
4. ğŸ’¡ **é£æ ¼é€‚é…**ï¼šä¿æŒç½‘æ–‡é£æ ¼ï¼Œç”ŸåŠ¨ã€æœ‰ç”»é¢æ„Ÿã€‚
"""

    # æ„å»º User Prompt
    user_message = ""
    
    # åŒºåˆ†æ˜¯å¦æœ‰é€‰ä¸­æ–‡æœ¬
    if chat_req.selected_text:
        user_message += f"ã€å¾…å¤„ç†æ–‡æœ¬ã€‘\n{chat_req.selected_text}\n\n"
        # âš ï¸ å¦‚æœæœ‰é€‰ä¸­æ–‡æœ¬ï¼Œä¸æä¾›é¢å¤–ä¸Šä¸‹æ–‡ï¼Œå¼ºåˆ¶AIåªå¤„ç†é€‰ä¸­éƒ¨åˆ†
        # ç§»é™¤äº† context_text çš„æ·»åŠ é€»è¾‘
    else:
        # å¦‚æœæ²¡æœ‰é€‰ä¸­æ–‡æœ¬ï¼Œä¸Šä¸‹æ–‡æ˜¯ç»­å†™çš„åŸºç¡€
        if chat_req.context_text:
            context_preview = chat_req.context_text[-2000:] if len(chat_req.context_text) > 2000 else chat_req.context_text
            user_message += f"ã€å½“å‰å‰æ–‡ã€‘\n...{context_preview}\n\n"
    
    user_message += f"ã€å½“å‰æŒ‡ä»¤ã€‘\n{chat_req.prompt}"

    # å®šä¹‰æµå¼ç”Ÿæˆå™¨
    async def event_generator():
        try:
            # ä½¿ç”¨ä¸¤é˜¶æ®µMCPç”Ÿæˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
            # è¿™æ ·å¯ä»¥è®©AIå…ˆæŸ¥èµ„æ–™ï¼ˆå¦‚ç™¾ç§‘ï¼‰ï¼Œå†å›ç­”
            async for chunk in user_ai_service.generate_text_stream_with_mcp(
                prompt=user_message,
                user_id=user_id,
                db_session=db, # æ³¨æ„ï¼šgenerate_text_stream_with_mcp å†…éƒ¨å¯èƒ½éœ€è¦ db_session æ¥è·å–å·¥å…·
                enable_mcp=chat_req.use_mcp,
                mcp_planning_prompt=None, # ä½¿ç”¨é»˜è®¤è§„åˆ’æç¤º
                system_prompt=system_prompt
            ):
                yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
            
            yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            logger.error(f"AI Chat Error: {str(e)}")
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"

    return create_sse_response(event_generator())
